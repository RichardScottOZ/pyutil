{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images and their bboxes in annotation files\n",
    "\n",
    "The bboxes of each image is contained in the annotation file (i.e., one JSON file per image). For the annotation format, see section *Train with the Image Format* in the [SageMaker Object Detection Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html) documentation.\n",
    "\n",
    "Recall the annotation structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"file\": \"haha.jpg\",\n",
    "   \"image_size\": [...]\n",
    "   \"annotations\": [\n",
    "      {\n",
    "         \"class_id\": 0,\n",
    "         \"left\": 300,\n",
    "         \"top\": 38,\n",
    "         \"width\": 100,\n",
    "         \"height\": 52\n",
    "      },\n",
    "      {...}\n",
    "   ],\n",
    "   \"categories\": [...]\n",
    "}\n",
    "```\n",
    "\n",
    "We'll loop over all annotation files in S3. For each annotation file, load the corresponding image, then plot image + bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prefer opencv, as with PIL there's no way to load single-channel jpg as rgb in-memory data.\n",
    "#from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "json_path = 's3://bucket/dataset/train_annotation/'\n",
    "img_path = 's3://bucket/dataset/train/'\n",
    "fs = s3fs.S3FileSystem(anon=False, profile_name='default')\n",
    "\n",
    "# Get the name of all JSON files.\n",
    "json_files = fs.ls(json_path)\n",
    "\n",
    "# Will plot images in two columns\n",
    "nrows, ncols = (len(json_files)+1)//2, 2\n",
    "w,h = 16, 18\n",
    "_, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(w,h))\n",
    "\n",
    "# Iterate through all annotation json files\n",
    "for i, json_fname in enumerate(json_files):\n",
    "    # Deserialize annotation JSON file to dictionary\n",
    "    d = json.loads(fs.cat(json_fname))\n",
    "\n",
    "    # Load image from S3 into 3-channel.\n",
    "    # NOTE: if using bytearray(), then pair with np.asarray().\n",
    "    img_fname = os.path.join(img_path, d['file'])\n",
    "    b = bytes(fs.cat(img_fname))\n",
    "    arr = np.frombuffer(b, dtype=np.uint8)\n",
    "    img = cv2.imdecode(arr, 1)\n",
    "\n",
    "    # Draw bboxes on image\n",
    "    for bbox in d['annotations']:\n",
    "        # bbox coordinates\n",
    "        x_min, y_min = bbox['left'], bbox['top']\n",
    "        x_max, y_max = x_min + bbox['width'], y_min + bbox['height']\n",
    "\n",
    "        # color to use (will round-robin r->g->b according to class_id)\n",
    "        cid = bbox['class_id']\n",
    "        color = [0,0,0]\n",
    "        color[cid % 3] = 255\n",
    "        cv2.rectangle(img, pt1=(x_min, y_min), pt2=(x_max, y_max), color=color, thickness=2)\n",
    "\n",
    "    # Add to plot figure\n",
    "    row, col = i//2, i%2\n",
    "    this_ax = ax[row][col]\n",
    "    this_ax.set_title(f'[img-{i:02}] {img_fname}')\n",
    "    this_ax.imshow(img)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
