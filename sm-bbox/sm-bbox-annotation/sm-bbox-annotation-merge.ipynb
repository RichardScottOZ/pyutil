{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge multiple annotated images into one\n",
    "\n",
    "This notebook demonstrates how to stack multiple images into one, where each source image has been annotated with bounding box. The source annotations and merged annotations are in JSON format according to [section *Train with the Image Format* in the SageMaker Object Detection Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html) documentation.\n",
    "\n",
    "The merge annotation will have the bboxes coordinates properly adjusted.\n",
    "\n",
    "Atd to recap, here's the annotation structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"file\": \"haha.jpg\",\n",
    "   \"image_size\": [...]\n",
    "   \"annotations\": [\n",
    "      {\n",
    "         \"class_id\": 0,\n",
    "         \"left\": 300,\n",
    "         \"top\": 38,\n",
    "         \"width\": 100,\n",
    "         \"height\": 52\n",
    "      },\n",
    "      {...}\n",
    "   ],\n",
    "   \"categories\": [...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import copy\n",
    "import cv2\n",
    "from itertools import chain\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from typing import Any, Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 6 images to group into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_profile = 'default'   # Use 'default' for default credential\n",
    "\n",
    "s3_prefix = 's3://bucket/dataset/train_annotation'\n",
    "group_size = 6\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False, profile_name=aws_profile)\n",
    "json_fnames: List[str] = fs.ls(s3_prefix)[:group_size]\n",
    "\n",
    "json_fnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 6 images + annotations from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(fname: str) -> np.ndarray:\n",
    "    # Read bytes from S3 into an ndarray\n",
    "    b = bytes(fs.cat(f's3://fuxin-marcverd/grouper/train/{fname}'))\n",
    "    arr = np.frombuffer(b, dtype=np.uint8)\n",
    "    \n",
    "    # Decode the jpg-bytes ndarray to a cv2 image (and force 3 channels).\n",
    "    return cv2.imdecode(arr,1)\n",
    "\n",
    "annotations: List[Dict[Any,Any]] = [json.loads(fs.cat(fname)) for fname in json_fnames]\n",
    "imgs: List[np.ndarray] = [load_img(d['file']) for d in annotations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: the code showed here can group variable-sized images. If all images are guaranteed to be the same size, then can also use `np.stack()`.\n",
    "\n",
    "## Compute target height & width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image heights: (136, 136, 136, 136, 136, 136)\n",
      "Image widths: (780, 780, 780, 780, 780, 780)\n",
      "Size of grouped image will be (816, 780)\n"
     ]
    }
   ],
   "source": [
    "# Get widths,heights of individual images\n",
    "heights, widths = zip(*[x.shape[:2] for x in imgs])\n",
    "print('Image heights:', heights)\n",
    "print('Image widths:', widths)\n",
    "\n",
    "# Compute width, height of grouped image\n",
    "h,w = sum(heights), max(widths)\n",
    "print('Size of grouped image will be', (h,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute offsets\n",
    "\n",
    "We also compute the y-offset for each image in the new picture. This offset determines the vertical starting point of each image.\n",
    "\n",
    "```\n",
    "+------------------+ => y = 0 \n",
    "| image-00         |\n",
    "+------------------+ => y = height of image-00\n",
    "| image-01         |\n",
    "+------------------+ => y = sum(heights of previous images)\n",
    "| ...              |\n",
    "+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 136, 272, 408, 544, 680])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_offsets: np.ndarray = np.cumsum(heights) - heights[0]\n",
    "y_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate a black RGB image (i.e., all-zero array)\n",
    "merged_arr = np.zeros((h,w,3), dtype=np.uint8)\n",
    "\n",
    "# Put images one by one.\n",
    "for img, offset in zip(imgs, y_offsets):\n",
    "    height = img.shape[0]\n",
    "    merged_arr[offset:offset+height,:,:] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recompute Bounding Boxes\n",
    "\n",
    "Recall this is the annotation structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"file\": \"REPLACE_ME\",\n",
    "   \"image_size\": [...]\n",
    "   \"annotations\": [\n",
    "      {\n",
    "         \"class_id\": 0,\n",
    "         \"left\": 300,\n",
    "         \"top\": 38,\n",
    "         \"width\": 100,\n",
    "         \"height\": 52\n",
    "      },\n",
    "   ],\n",
    "   \"categories\": [...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "0: 2055_1_1.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 38, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 60, 40, 50)\n",
      "----\n",
      "136: 2055_1_1_flipped.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 174, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 196, 40, 50)\n",
      "----\n",
      "272: 2055_1_1_norm.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 310, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 332, 40, 50)\n",
      "----\n",
      "408: 2055_1_1_norm_flipped.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 446, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 468, 40, 50)\n",
      "----\n",
      "544: 2055_1_1_synth.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 582, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 604, 40, 50)\n",
      "----\n",
      "680: 2055_1_1_synth_flipped.jpg\n",
      "ori: left, top, width, height: (300, 38, 100, 52)\n",
      "adj: left, top, width, height: (300, 718, 100, 52)\n",
      "ori: left, top, width, height: (60, 60, 40, 50)\n",
      "adj: left, top, width, height: (60, 740, 40, 50)\n"
     ]
    }
   ],
   "source": [
    "ann2 = []\n",
    "\n",
    "for d, offset in zip(annotations, y_offsets):\n",
    "    print('----')\n",
    "    print(f'{offset}:', d['file'])\n",
    "    d2 = copy.deepcopy(d)\n",
    "    for bbox in d2['annotations']:\n",
    "        print('ori: left, top, width, height:', (bbox['left'], bbox['top'], bbox['width'], bbox['height']))\n",
    "        bbox['top'] += int(offset)    # Need int() otherwise result is np.int64 and json.dumps choke on it by default.\n",
    "        print('adj: left, top, width, height:', (bbox['left'], bbox['top'], bbox['width'], bbox['height']))\n",
    "    ann2.append(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge annotations and Ensure consistent class id\n",
    "\n",
    "We enforce a new mapping of `class_id => class_name` in the merge image. This anticipates unintended cases such as `class 0 => cat` in one annotation, but `class 0 => dog` in another annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'image-000.jpg',\n",
       " 'image_size': [{'width': 780, 'height': 816, 'depth': 3}],\n",
       " 'annotations': [{'class_id': 0,\n",
       "   'left': 300,\n",
       "   'top': 38,\n",
       "   'width': 100,\n",
       "   'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 60, 'width': 40, 'height': 50},\n",
       "  {'class_id': 0, 'left': 300, 'top': 174, 'width': 100, 'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 196, 'width': 40, 'height': 50},\n",
       "  {'class_id': 0, 'left': 300, 'top': 310, 'width': 100, 'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 332, 'width': 40, 'height': 50},\n",
       "  {'class_id': 0, 'left': 300, 'top': 446, 'width': 100, 'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 468, 'width': 40, 'height': 50},\n",
       "  {'class_id': 0, 'left': 300, 'top': 582, 'width': 100, 'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 604, 'width': 40, 'height': 50},\n",
       "  {'class_id': 0, 'left': 300, 'top': 718, 'width': 100, 'height': 52},\n",
       "  {'class_id': 1, 'left': 60, 'top': 740, 'width': 40, 'height': 50}],\n",
       " 'categories': [{'class_id': 0, 'name': 'dog'},\n",
       "  {'class_id': 1, 'name': 'cat'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fname = 'image-000.jpg'\n",
    "\n",
    "new_cat = [\n",
    "    {\"class_id\": 0, \"name\": \"dog\"},\n",
    "    {\"class_id\": 1, \"name\": \"cat\"},\n",
    "]\n",
    "\n",
    "merged_ann = {\n",
    "   \"file\": merged_fname,\n",
    "   \"image_size\": [{\n",
    "       'width': merged_arr.shape[1],\n",
    "       'height': merged_arr.shape[0],\n",
    "       'depth': merged_arr.shape[2]\n",
    "   }],\n",
    "   \"annotations\": [bbox for bbox in chain(*(d['annotations'] for d in ann2))],\n",
    "   \"categories\": new_cat    \n",
    "}\n",
    "\n",
    "merged_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display merged image with bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(img: np.ndarray, d: Dict[str, Any], inplace=False) -> np.ndarray:\n",
    "    im = img.copy() if not inplace else img\n",
    "    for bbox in d['annotations']:\n",
    "        # bbox coordinates\n",
    "        x_min, y_min = bbox['left'], bbox['top']\n",
    "        x_max, y_max = x_min + bbox['width'], y_min + bbox['height']\n",
    "\n",
    "        # color to use (will round-robin r->g->b according to class_id)\n",
    "        cid = bbox['class_id']\n",
    "        color = [0,0,0]\n",
    "        color[cid % 3] = 255\n",
    "        cv2.rectangle(im, pt1=(x_min, y_min), pt2=(x_max, y_max), color=color, thickness=2)\n",
    "\n",
    "    return im\n",
    "\n",
    "img_with_bbox = draw_bboxes(merged_arr, merged_ann)\n",
    "\n",
    "plt.figure(figsize=(9,9));\n",
    "plt.title('Enlarged')\n",
    "plt.imshow(img_with_bbox)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write merged image...\n",
      "Write merged annotation...\n",
      "Write merged image with bboxes for debugging...\n"
     ]
    }
   ],
   "source": [
    "print(\"Write merged image...\")\n",
    "with fs.open(f's3://bucket/dataset/train/{merged_fname}', 'wb') as f:\n",
    "    content = cv2.imencode('.jpg', merged_arr)[1].tostring()\n",
    "    f.write(content)\n",
    "\n",
    "print(\"Write merged annotation...\")\n",
    "with fs.open('s3://bucket/dataset/train_annotation/image-000.json', 'wb') as f:\n",
    "    content = json.dumps(merged_ann).encode(encoding='utf-8', errors='strict')\n",
    "    f.write(content)\n",
    "\n",
    "print(\"Write merged image with bboxes for debugging...\")\n",
    "with fs.open('s3://bucket/dataset/train_annotated/image-000-bbox.jpg', 'wb') as f:\n",
    "    content = cv2.imencode('.jpg', img_with_bbox)[1].tostring()\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
